<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Perceptron & MLP Visualizer</title>
    <script src="https://cdn.plot.ly/plotly-2.24.1.min.js"></script>
    <style>
        :root {
            --primary: #2563eb;
            --bg: #f8fafc;
            --card: #ffffff;
            --text: #1e293b;
        }

        body {
            font-family: 'Segoe UI', system-ui, sans-serif;
            background-color: var(--bg);
            color: var(--text);
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        h1 { margin-bottom: 10px; }
        p { color: #64748b; margin-bottom: 30px; }

        .container {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            max-width: 1200px;
            width: 100%;
            justify-content: center;
        }

        .controls {
            flex: 1;
            min-width: 300px;
            background: var(--card);
            padding: 25px;
            border-radius: 12px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
            height: fit-content;
        }

        .graph-container {
            flex: 2;
            min-width: 400px;
            background: var(--card);
            padding: 10px;
            border-radius: 12px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
            height: 500px;
        }

        .control-group { margin-bottom: 20px; }
        label { display: block; margin-bottom: 8px; font-weight: 600; font-size: 0.9rem; }
        
        select, input[type="number"] {
            width: 100%;
            padding: 10px;
            border: 1px solid #cbd5e1;
            border-radius: 6px;
            font-size: 1rem;
            margin-bottom: 5px;
        }

        .buttons { display: flex; gap: 10px; margin-top: 20px; }
        
        button {
            flex: 1;
            padding: 12px;
            border: none;
            border-radius: 6px;
            font-weight: 600;
            cursor: pointer;
            transition: opacity 0.2s;
        }

        #trainBtn { background-color: var(--primary); color: white; }
        #resetBtn { background-color: #ef4444; color: white; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        button:hover:not(:disabled) { opacity: 0.9; }

        .stats {
            margin-top: 20px;
            padding-top: 20px;
            border-top: 1px solid #e2e8f0;
            font-family: monospace;
            font-size: 0.9rem;
        }

        .stat-row { display: flex; justify-content: space-between; margin-bottom: 5px; }
        .success { color: #16a34a; font-weight: bold; }
        .fail { color: #dc2626; font-weight: bold; }

    </style>
</head>
<body>

    <h1>Perceptron & MLP Visualizer</h1>
    <p>Visualize how a neural network learns logic gates. Switch to <strong>XOR</strong> to see the Multi-Layer Perceptron.</p>

    <div class="container">
        <div class="controls">
            <div class="control-group">
                <label for="gateSelect">Logic Gate</label>
                <select id="gateSelect">
                    <option value="AND">AND (Linear)</option>
                    <option value="OR">OR (Linear)</option>
                    <option value="NAND">NAND (Linear)</option>
                    <option value="XOR">XOR (Non-Linear / MLP)</option>
                </select>
            </div>

            <div class="control-group">
                <label for="learningRate">Learning Rate (Alpha)</label>
                <input type="number" id="learningRate" value="0.05" step="0.01" min="0.001" max="1">
            </div>

            <div class="buttons">
                <button id="trainBtn">Start Training</button>
                <button id="resetBtn">Reset</button>
            </div>

            <div class="stats" id="statsPanel">
                <div class="stat-row"><span>Epoch:</span> <span id="epochVal">0</span></div>
                <div class="stat-row"><span>Total Error:</span> <span id="errorVal">0</span></div>
                <div class="stat-row" id="weightsDisplay"></div>
                <div style="margin-top:10px" id="statusMsg">Ready to train.</div>
            </div>
        </div>

        <div class="graph-container" id="plotDiv"></div>
    </div>

    <script>
        // --- Configuration & State ---
        const gates = {
            AND:  { data: [[0,0,0], [0,1,0], [1,0,0], [1,1,1]], type: 'single' },
            OR:   { data: [[0,0,0], [0,1,1], [1,0,1], [1,1,1]], type: 'single' },
            NAND: { data: [[0,0,1], [0,1,1], [1,0,1], [1,1,0]], type: 'single' },
            XOR:  { data: [[0,0,0], [0,1,1], [1,0,1], [1,1,0]], type: 'mlp' }
        };

        let currentGate = 'AND';
        let isTraining = false;
        let animationId = null;
        let epoch = 0;
        
        // Single Perceptron State
        let weights = [Math.random() * 2 - 1, Math.random() * 2 - 1]; // w1, w2
        let bias = Math.random() * 2 - 1;

        // MLP State (2-2-1 Architecture for XOR)
        // Hidden Layer (2 neurons)
        let hiddenWeights = [
            [Math.random(), Math.random()], // Neuron 1 [w1, w2]
            [Math.random(), Math.random()]  // Neuron 2 [w1, w2]
        ];
        let hiddenBias = [Math.random(), Math.random()];
        // Output Layer (1 neuron)
        let outputWeights = [Math.random(), Math.random()];
        let outputBias = Math.random();

        // --- DOM Elements ---
        const plotDiv = document.getElementById('plotDiv');
        const epochDisplay = document.getElementById('epochVal');
        const errorDisplay = document.getElementById('errorVal');
        const statusMsg = document.getElementById('statusMsg');
        const trainBtn = document.getElementById('trainBtn');

        // --- Core Math Functions ---
        // Step function for single perceptron
        const step = (n) => n >= 0 ? 1 : 0;
        
        // Sigmoid for MLP
        const sigmoid = (x) => 1 / (1 + Math.exp(-x));
        const sigmoidDeriv = (x) => x * (1 - x); // derivative assuming x is already sigmoid(output)

        // --- Initialization ---
        function init() {
            resetWeights();
            plotGraph();
            updateStats(0);
        }

        function resetWeights() {
            // Reset Single Perceptron
            weights = [Math.random()-0.5, Math.random()-0.5];
            bias = Math.random()-0.5;

            // Reset MLP
            hiddenWeights = [[Math.random()-0.5, Math.random()-0.5], [Math.random()-0.5, Math.random()-0.5]];
            hiddenBias = [Math.random()-0.5, Math.random()-0.5];
            outputWeights = [Math.random()-0.5, Math.random()-0.5];
            outputBias = Math.random()-0.5;

            epoch = 0;
            isTraining = false;
            if(animationId) cancelAnimationFrame(animationId);
            trainBtn.innerText = "Start Training";
            trainBtn.disabled = false;
            statusMsg.innerText = "Ready to train.";
            statusMsg.className = "";
            plotGraph();
        }

        // --- Training Logic: Single Perceptron ---
        function trainSinglePerceptron(lr) {
            let totalError = 0;
            const data = gates[currentGate].data;

            for(let i=0; i<data.length; i++) {
                const [x1, x2, target] = data[i];
                const weightedSum = x1 * weights[0] + x2 * weights[1] + bias;
                const prediction = step(weightedSum);
                const error = target - prediction;

                if (error !== 0) {
                    weights[0] += lr * error * x1;
                    weights[1] += lr * error * x2;
                    bias += lr * error;
                    totalError += Math.abs(error);
                }
            }
            return totalError;
        }

        // --- Training Logic: MLP (Backpropagation) ---
        function trainMLP(lr) {
            let totalError = 0;
            const data = gates[currentGate].data;

            for(let i=0; i<data.length; i++) {
                const [x1, x2, target] = data[i];

                // 1. Forward Pass
                // Hidden Layer
                let h1_in = x1 * hiddenWeights[0][0] + x2 * hiddenWeights[0][1] + hiddenBias[0];
                let h1_out = sigmoid(h1_in);
                
                let h2_in = x1 * hiddenWeights[1][0] + x2 * hiddenWeights[1][1] + hiddenBias[1];
                let h2_out = sigmoid(h2_in);

                // Output Layer
                let o_in = h1_out * outputWeights[0] + h2_out * outputWeights[1] + outputBias;
                let final_out = sigmoid(o_in);

                // Calculate Error
                let error = target - final_out;
                totalError += Math.abs(error);

                // 2. Backward Pass
                // Output Gradients
                // dError/dOutput * dOutput/dInput
                let d_output = error * sigmoidDeriv(final_out);

                // Hidden Gradients
                let error_h1 = d_output * outputWeights[0];
                let error_h2 = d_output * outputWeights[1];
                
                let d_h1 = error_h1 * sigmoidDeriv(h1_out);
                let d_h2 = error_h2 * sigmoidDeriv(h2_out);

                // 3. Update Weights
                outputWeights[0] += lr * d_output * h1_out;
                outputWeights[1] += lr * d_output * h2_out;
                outputBias     += lr * d_output;

                hiddenWeights[0][0] += lr * d_h1 * x1;
                hiddenWeights[0][1] += lr * d_h1 * x2;
                hiddenBias[0]      += lr * d_h1;

                hiddenWeights[1][0] += lr * d_h2 * x1;
                hiddenWeights[1][1] += lr * d_h2 * x2;
                hiddenBias[1]      += lr * d_h2;
            }
            return totalError;
        }

        // --- Training Loop ---
        function startTraining() {
            if (isTraining) return;
            isTraining = true;
            trainBtn.disabled = true;
            statusMsg.innerText = "Training...";
            
            const lr = parseFloat(document.getElementById('learningRate').value);
            const gateType = gates[currentGate].type;

            function loop() {
                if (!isTraining) return;

                // Run a batch of epochs for speed
                let currentError = 0;
                let stepsPerFrame = gateType === 'mlp' ? 50 : 5; // MLP needs more steps to converge visually

                for(let k=0; k<stepsPerFrame; k++) {
                    epoch++;
                    if(gateType === 'single') {
                        currentError = trainSinglePerceptron(lr);
                    } else {
                        currentError = trainMLP(lr);
                    }
                }

                updateStats(currentError);
                plotGraph();

                // Stop conditions
                let converged = false;
                if(gateType === 'single' && currentError === 0) converged = true;
                if(gateType === 'mlp' && currentError < 0.1) converged = true; // Approx convergence for MLP

                if (converged) {
                    isTraining = false;
                    trainBtn.disabled = false;
                    statusMsg.innerText = `Converged in ${epoch} epochs!`;
                    statusMsg.className = "success";
                } else if (epoch > 10000) {
                    isTraining = false;
                    trainBtn.disabled = false;
                    statusMsg.innerText = "Stopped (Max Epochs Reached).";
                    statusMsg.className = "fail";
                } else {
                    animationId = requestAnimationFrame(loop);
                }
            }
            loop();
        }

        // --- Visualization (Plotly) ---
        function plotGraph() {
            const dataPoints = gates[currentGate].data;
            const type = gates[currentGate].type;

            // 1. Scatter plot for the logic gate points (0s and 1s)
            const x0 = [], y0 = [], x1 = [], y1 = [];
            dataPoints.forEach(pt => {
                if(pt[2] === 0) { x0.push(pt[0]); y0.push(pt[1]); }
                else { x1.push(pt[0]); y1.push(pt[1]); }
            });

            const trace0 = {
                x: x0, y: y0, mode: 'markers', type: 'scatter',
                name: 'Output 0', marker: { color: 'red', size: 14, symbol: 'circle-open', line: {width: 2} }
            };
            const trace1 = {
                x: x1, y: y1, mode: 'markers', type: 'scatter',
                name: 'Output 1', marker: { color: 'blue', size: 14, symbol: 'circle' }
            };

            const traces = [trace0, trace1];

            // 2. Decision Boundary
            if (type === 'single') {
                // Line: w1*x + w2*y + b = 0  =>  y = -(w1*x + b) / w2
                // We create two points to draw the line
                const xRange = [-0.5, 1.5];
                let lineY = [];
                
                // Avoid division by zero
                if (Math.abs(weights[1]) < 0.0001) {
                    // Vertical line case logic (omitted for simplicity in basic demo)
                    lineY = [-10, 10]; 
                } else {
                    lineY = xRange.map(x => -(weights[0] * x + bias) / weights[1]);
                }

                const boundaryTrace = {
                    x: xRange, y: lineY, mode: 'lines', name: 'Boundary',
                    line: { color: 'black', width: 2, dash: 'dash' }
                };
                traces.push(boundaryTrace);
            } 
            else if (type === 'mlp') {
                // Heatmap for MLP to show non-linear boundary
                const resolution = 25; // Keep low for performance during animation
                const xGrid = [], yGrid = [], zGrid = [];
                
                for(let i=0; i<=resolution; i++) {
                    let r = i/resolution * 2 - 0.5; // range -0.5 to 1.5
                    xGrid.push(r);
                }
                for(let i=0; i<=resolution; i++) {
                    let r = i/resolution * 2 - 0.5;
                    yGrid.push(r);
                }

                for(let i=0; i<yGrid.length; i++) {
                    let row = [];
                    for(let j=0; j<xGrid.length; j++) {
                        // Forward pass prediction for grid point
                        let x1 = xGrid[j];
                        let x2 = yGrid[i];
                        
                        let h1 = sigmoid(x1 * hiddenWeights[0][0] + x2 * hiddenWeights[0][1] + hiddenBias[0]);
                        let h2 = sigmoid(x1 * hiddenWeights[1][0] + x2 * hiddenWeights[1][1] + hiddenBias[1]);
                        let out = sigmoid(h1 * outputWeights[0] + h2 * outputWeights[1] + outputBias);
                        row.push(out);
                    }
                    zGrid.push(row);
                }

                const contourTrace = {
                    z: zGrid, x: xGrid, y: yGrid, type: 'contour',
                    colorscale: [[0, 'rgba(255,0,0,0.3)'], [1, 'rgba(0,0,255,0.3)']],
                    showscale: false, contours: { showlines: false }
                };
                // Put contour at bottom
                traces.unshift(contourTrace);
            }

            const layout = {
                xaxis: { range: [-0.5, 1.5], title: 'Input 1' },
                yaxis: { range: [-0.5, 1.5], title: 'Input 2', scaleanchor: "x" },
                margin: { t: 20, l: 40, r: 20, b: 40 },
                showlegend: true,
                legend: { x: 0, y: 1 }
            };

            Plotly.newPlot('plotDiv', traces, layout, {responsive: true, displayModeBar: false});
        }

        function updateStats(err) {
            epochDisplay.innerText = epoch;
            errorDisplay.innerText = err.toFixed(4);
        }

        // --- Event Listeners ---
        document.getElementById('trainBtn').addEventListener('click', startTraining);
        
        document.getElementById('resetBtn').addEventListener('click', () => {
            resetWeights();
        });

        document.getElementById('gateSelect').addEventListener('change', (e) => {
            currentGate = e.target.value;
            resetWeights();
        });

        // Initialize on Load
        init();

    </script>
</body>
</html>